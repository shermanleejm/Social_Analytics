{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitf7dc2741bafe4a9b89002a7641fa85c3",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "swords = set(stopwords.words('english'))\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 82417 entries, 0 to 39928\nData columns (total 3 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   name       82417 non-null  object\n 1   message    82417 non-null  object\n 2   timestamp  82417 non-null  object\ndtypes: object(3)\nmemory usage: 2.5+ MB\n"
    }
   ],
   "source": [
    "df = pd.read_json(\"./data/data71.json\")\n",
    "df1 = pd.read_json(\"./data/data70.json\")\n",
    "\n",
    "df = pd.concat([df, df1])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "universities = [\n",
    "    \"Singapore Management University|smu\",\n",
    "    \"nanyang technological university|ntu\",\n",
    "    \"National University of Singapore|nus\",\n",
    "    \"Singapore University of Technology and Design|sutd\"\n",
    "]\n",
    "\n",
    "keywords = []\n",
    "with open(\"./data/keywords.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        keywords.append(line.strip())\n",
    "\n",
    "infoSys = \"information systems|it|information technology|data analytics|computer science|com|computer|info systems|info sys\"\n",
    "simplifiedInfoSys = \"computer|com|infosys|information systems|analytics|smart city\"\n",
    "simplifiedJC = \"rank|a-level|a level|\"\n",
    "\n",
    "poly = []\n",
    "with open(\"./data/poly.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        poly.append(line.strip()) \n",
    "\n",
    "lowtier = []\n",
    "with open(\"./data/lowTierJC.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        lowtier.append(line.strip()) \n",
    "\n",
    "midtier = []\n",
    "with open(\"./data/midTierJC.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        midtier.append(line.strip()) \n",
    "\n",
    "hightier = []\n",
    "with open(\"./data/highTierJC.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        hightier.append(line.strip()) \n",
    "\n",
    "\n",
    "'''\n",
    "The Positive, Negative and Neutral scores represent the proportion of text that falls in these categories. \n",
    "This means our sentence was rated as 67% Positive, 33% Neutral and 0% Negative. Hence all these should add up to 1.\n",
    "The Compound score is a metric that calculates the sum of all the lexicon ratings \n",
    "which have been normalized between -1(most extreme negative) and +1 (most extreme positive).\n",
    "'''\n",
    "\n",
    "def getScore(sentence): # return dict, e.g. --> {'neg': 0.0, 'neu': 0.326, 'pos': 0.674, 'compound': 0.7351}\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    return analyser.polarity_scores(sentence)\n",
    "\n",
    "def writeFile(filepath, headerArr, uni, startYear, endYear, terms, domain=\"\"):\n",
    "    df2 = pd.read_json(\"./data/data71.json\")\n",
    "    df1 = pd.read_json(\"./data/data70.json\")\n",
    "    df1[\"timestamp\"] = df1[\"timestamp\"].astype(str)\n",
    "    df = pd.concat([df2, df1])\n",
    "\n",
    "    f = open(filepath, \"w+\")\n",
    "\n",
    "    csvWriter = csv.writer(f)\n",
    "    csvWriter.writerow(headerArr)\n",
    "\n",
    "    for year in range(startYear, endYear + 1):\n",
    "\n",
    "        dfYear = df[df[\"timestamp\"].str.contains(str(year))]\n",
    "        yearStr = str(year)\n",
    "\n",
    "        for term in terms:\n",
    "\n",
    "            if domain == \"\" :\n",
    "                listOfComments = dfYear[ dfYear[\"message\"].str.contains(term, case=False) & dfYear[\"message\"].str.contains(uni, case=False)][\"message\"].values.tolist()\n",
    "            else :\n",
    "                listOfComments = dfYear[ dfYear[\"message\"].str.contains(term, case=False) & dfYear[\"message\"].str.contains(uni, case=False) & dfYear[\"message\"].str.contains(domain, case=False)][\"message\"].values.tolist()\n",
    "\n",
    "            score = 0\n",
    "            numOfComments = len(listOfComments) \n",
    "            # negative means < -0.10\n",
    "            # positive means > 0.10\n",
    "            # neutral mean >= -0.10 and <= 0.10\n",
    "            neg_count = 0\n",
    "            pos_count = 0\n",
    "            neu_count = 0\n",
    "\n",
    "            for comment in listOfComments:\n",
    "                temp_score = getScore(comment)[\"compound\"]\n",
    "                score += temp_score\n",
    "                if temp_score < -0.10:\n",
    "                    neg_count += 1\n",
    "                elif temp_score > 0.10:\n",
    "                    pos_count += 1\n",
    "                else:\n",
    "                    neu_count += 1\n",
    "\n",
    "            overallScore = 0\n",
    "            if numOfComments != 0:\n",
    "                overallScore = score / numOfComments\n",
    "            row = [year, term, overallScore, numOfComments, neg_count, neu_count, pos_count]\n",
    "            csvWriter.writerow(row)\n",
    "    f.close()\n",
    "\n",
    "def printWeightiestSentences(filepath, headerArr, uni, startYear, endYear, terms, numOfSentences, domain=\"\"):\n",
    "    if domain != \"\" :\n",
    "        uni += \"|\" + domain\n",
    "\n",
    "    f = open(filepath, \"w+\")\n",
    "\n",
    "    csvWriter = csv.writer(f)\n",
    "    csvWriter.writerow(headerArr)\n",
    "\n",
    "    for year in range(startYear, endYear + 1):\n",
    "        df1 = pd.read_json(\"./data/data70.json\")\n",
    "        df2 = pd.read_json(\"./data/data71.json\")\n",
    "        df1[\"timestamp\"] = df1[\"timestamp\"].astype(str)\n",
    "        df = pd.concat([df1, df2])\n",
    "\n",
    "        yearStr = str(year)\n",
    "        dfYear = df[df[\"timestamp\"].str.contains(yearStr, na=False)]\n",
    "        for term in terms:\n",
    "\n",
    "            if domain == \"\" :\n",
    "                listOfComments = dfYear[ dfYear[\"message\"].str.contains(term, case=False) & dfYear[\"message\"].str.contains(uni, case=False)][\"message\"].values.tolist()\n",
    "            else :\n",
    "                listOfComments = dfYear[ dfYear[\"message\"].str.contains(term, case=False) & dfYear[\"message\"].str.contains(uni, case=False) & dfYear[\"message\"].str.contains(domain, case=False)][\"message\"].values.tolist()\n",
    "\n",
    "            vectorizer = TfidfVectorizer(stop_words=swords)\n",
    "\n",
    "            X = vectorizer.fit_transform(listOfComments)\n",
    "\n",
    "            feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "            vocab = vectorizer.vocabulary_\n",
    "\n",
    "            unsorted_result = {}\n",
    "\n",
    "            for i in range(len(list(X.toarray()))) :\n",
    "                row = list(list(X.toarray())[i])\n",
    "                unsorted_result[listOfComments[i]] = sum(row)\n",
    "            \n",
    "            result = pd.DataFrame()\n",
    "            result[\"sentence\"] = unsorted_result.keys()\n",
    "            result[\"value\"] = unsorted_result.values()\n",
    "            df = result.sort_values(by=[\"value\"], ascending=False)\n",
    "            top10sentences = df.nlargest(num, \"value\")[\"sentence\"].tolist()\n",
    "            top10values = df.nlargest(num, \"value\")[\"value\"].tolist()\n",
    "            for i in range(num):\n",
    "                # line = str(year) + \",\" + uni + \",\" + term + \",\\\"\" + top10sentences[i] + \"\\\",\" + str(top10values[i]) + \"\\n\"\n",
    "                tempArr = [str(year), uni, term, top10sentences[i], top10values[i]]\n",
    "                csvWriter.writerow(tempArr)\n",
    "                f.write(line)\n",
    "                \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Diagram of result dataframe\n",
    "+------+--------+--------+-----+------+----\n",
    "| Year |   NP   |   SP   | ... | ACJC | ... \n",
    "+------+--------+--------+-----+------+----\n",
    "| 2014 | 0.9872 | -0.023 | ... | 0.33 | ...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JC Overall\n",
    "for uni in universities:\n",
    "    uniName = uni.split(\"|\")[-1]\n",
    "    pathname = f\"./output/{uniName} - JC (Overall).csv\"\n",
    "    header = \"year,score\\n\"\n",
    "\n",
    "    writeFile(pathname, header, uni, 2014, 2020, simplifiedJC, simplifiedInfoSys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low tier JC sentiment\n",
    "for uniRegex in universities:\n",
    "    uniName = uniRegex.split(\"|\")[-1]\n",
    "    pathname = f\"./output/{uniName} - lowtier.csv\"\n",
    "    header = [\"year\", \"search term\", \"sentiment score\", \"Number of comments\"]\n",
    "    start = 2014\n",
    "    end = 2021\n",
    "    searchTerms = lowtier\n",
    "    print (lowtier)\n",
    "    domain = simplifiedInfoSys\n",
    "\n",
    "    writeFile(pathname, header, uniRegex, start, end, searchTerms, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low tier jc weighted sentences\n",
    "for uniRegex in universities:\n",
    "    uniName = uniRegex.split(\"|\")[-1]\n",
    "    pathname = f\"./output/{uniName} - lowtier.csv\"\n",
    "    header = [\"year\", \"search term\", \"sentence\", \"tfidf score\"]\n",
    "    start = 2014\n",
    "    end = 2021\n",
    "    searchTerms = lowtier\n",
    "    domain = simplifiedInfoSys\n",
    "\n",
    "    writeFile(pathname, header, uniRegex, start, end, searchTerms, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid tier JC\n",
    "for uniRegex in universities:\n",
    "    uniName = uniRegex.split(\"|\")[-1]\n",
    "    pathname = f\"./output/{uniName} - midtier.csv\"\n",
    "    header = [\"year\", \"search term\", \"sentiment score\", \"Number of comments\"]\n",
    "    start = 2014\n",
    "    end = 2021\n",
    "    searchTerms = midtier\n",
    "    domain = simplifiedInfoSys\n",
    "\n",
    "    writeFile(pathname, header, uniRegex, start, end, searchTerms, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high tier JC\n",
    "for uniRegex in universities:\n",
    "    uniName = uniRegex.split(\"|\")[-1]\n",
    "    pathname = f\"./output/{uniName} - hightier.csv\"\n",
    "    header = [\"year\", \"search term\", \"sentiment score\", \"Number of comments\"]\n",
    "    start = 2014\n",
    "    end = 2021\n",
    "    searchTerms = hightier\n",
    "    domain = simplifiedInfoSys\n",
    "\n",
    "    writeFile(pathname, header, uniRegex, start, end, searchTerms, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Singapore Management University|smu\nSingapore Management University|smu|computer|com|infosys|information systems|analytics|smart city\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7a1bea14657a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplifiedInfoSys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muniRegex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mwriteFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniRegex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearchTerms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-55c9dca39c3c>\u001b[0m in \u001b[0;36mwriteFile\u001b[0;34m(filepath, headerArr, uni, startYear, endYear, terms, domain)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mlistOfComments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfYear\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mdfYear\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mdfYear\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muni\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mnumOfComments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistOfComments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1950\u001b[0m                 )\n\u001b[1;32m   1951\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mcontains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   2759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m         result = str_contains(\n\u001b[0;32m-> 2761\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2762\u001b[0m         )\n\u001b[1;32m   2763\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mstr_contains\u001b[0;34m(arr, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0muppered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muppered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_na_map\u001b[0;34m(f, arr, na_result, dtype)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mna_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_map_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_map_object\u001b[0;34m(f, arr, na_mask, na_value, dtype)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# Reraise the exception if callable `f` got wrong number of args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    449\u001b[0m             )\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# combined tiers JC\n",
    "lowtierRegex = \"|\".join(lowtier)\n",
    "midtierRegex = \"|\".join(midtier)\n",
    "hightierRegex = \"|\".join(hightier)\n",
    "\n",
    "combinedTiers = [lowtierRegex, midtierRegex, hightierRegex]\n",
    "\n",
    "for uniRegex in universities:\n",
    "    uniName = uniRegex.split(\"|\")[-1]\n",
    "    pathname = f\"./output/{uniName} - JC combined tiers.csv\"\n",
    "    header = [\"year\", \"search term\", \"sentiment score\", \"Number of comments\", \"Negative Comments\", \"Neutral Comments\", \"Positive Comments\"]\n",
    "    start = 2014\n",
    "    end = 2021\n",
    "    searchTerms = combinedTiers\n",
    "    domain = simplifiedInfoSys\n",
    "    print (uniRegex)\n",
    "    writeFile(pathname, header, uniRegex, start, end, searchTerms, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Singapore Management University|smu\nnanyang technological university|ntu\nNational University of Singapore|nus\nSingapore University of Technology and Design|sutd\n"
    }
   ],
   "source": [
    "# combined tiers JC without infosys\n",
    "lowtierRegex = \"|\".join(lowtier)\n",
    "midtierRegex = \"|\".join(midtier)\n",
    "hightierRegex = \"|\".join(hightier)\n",
    "\n",
    "combinedTiers = [lowtierRegex, midtierRegex, hightierRegex]\n",
    "\n",
    "for uniRegex in universities:\n",
    "    uniName = uniRegex.split(\"|\")[-1]\n",
    "    pathname = f\"./output/{uniName} - JC combined tiers without infosys.csv\"\n",
    "    header = [\"year\", \"search term\", \"sentiment score\", \"Number of comments\", \"Negative Comments\", \"Neutral Comments\", \"Positive Comments\"]\n",
    "    start = 2014\n",
    "    end = 2021\n",
    "    searchTerms = combinedTiers\n",
    "    domain = simplifiedInfoSys\n",
    "    print (uniRegex)\n",
    "    writeFile(pathname, header, uniRegex, start, end, searchTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polytechnics\n",
    "for uniRegex in universities:\n",
    "    uniName = uniRegex.split(\"|\")[-1]\n",
    "    pathname = f\"./output/{uniName} - poly.csv\"\n",
    "    header = [\"year\", \"search term\", \"sentiment score\", \"Number of comments\"]\n",
    "    start = 2014\n",
    "    end = 2021\n",
    "    searchTerms = poly\n",
    "    domain = simplifiedInfoSys\n",
    "\n",
    "    writeFile(pathname, header, uniRegex, start, end, searchTerms, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}